{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2a8144-6350-4b8d-b383-7c77664ebc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kooplearn\n",
      "  Downloading kooplearn-1.1.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.12/site-packages (from kooplearn) (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from kooplearn) (1.6.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from kooplearn) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kooplearn) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->kooplearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->kooplearn) (3.5.0)\n",
      "Downloading kooplearn-1.1.3-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: kooplearn\n",
      "Successfully installed kooplearn-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import importlib\n",
    "for module in ['kooplearn', 'matplotlib']:\n",
    "    try:\n",
    "        importlib.import_module(module)\n",
    "    except ImportError:\n",
    "        %pip install {module}\n",
    "import kooplearn\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from kooplearn.models import NystroemKernel\n",
    "from kooplearn.data import traj_to_contexts\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c24708e-625d-4e7e-822a-dd54dbb459d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1029/1494444423.py:5: DtypeWarning: Columns (36,37,38,39) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_2021 = pd.read_csv('data_2021.csv',sep=';')\n"
     ]
    }
   ],
   "source": [
    "actual_path = os.getcwd()\n",
    "os.chdir('/home/onyxia/work/Dynamical_system/data')\n",
    "data_2019 = pd.read_csv('data_2019.csv',sep=';')\n",
    "data_2020 = pd.read_csv('data_2020.csv',sep=';')\n",
    "data_2021 = pd.read_csv('data_2021.csv',sep=';')\n",
    "data_2022 = pd.read_csv('data_2022.csv',sep=';')\n",
    "prices = pd.read_csv('France.csv')\n",
    "os.chdir(actual_path)\n",
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c00119-7a0b-4fa9-8ff1-2b14df462a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = pd.concat([data_2019,data_2020,data_2021,data_2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7ac7deb-eb69-4a1f-a76d-9bb9cdd5cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = whole_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c456e266-da0c-4260-a5c1-66c77d445467",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_drop = ['Périmètre','Prévision J-1','Prévision J',\n",
    "                ' Stockage batterie',\n",
    "                'Déstockage batterie','Eolien terrestre',\n",
    "                'Eolien offshore',\n",
    "                'Unnamed: 40','Nature']\n",
    "#the variables related to the batteries and both the ones \n",
    "#containing informations about offshore and onshore\n",
    "#wind are deleted because they only contain NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac32807e-7efe-4e66-bc3b-8269d1cb371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data = whole_data.drop(list_to_drop,axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01126bd-0173-4a81-884e-fabbaa61cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data = use_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef201933-b981-4f04-a552-217c54daa712",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data.loc[:, 'Heures'] = use_data['Heures'].apply(lambda x: f\"{x}:00\" if len(x.split(':')) == 2 else x)\n",
    "use_data['Heures'] = pd.to_timedelta(use_data['Heures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce5eaef0-5c4b-4884-8a8b-3bc69d820303",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data['date'] = pd.to_datetime(use_data['Date']) + use_data['Heures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3aca6a75-8627-4f71-8893-380527b87bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data.drop(['Heures'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f878f63-113e-491e-b081-55bee3eab75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_period = prices[prices['Datetime (Local)'] >= '2019-01-01 00:00:00'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af3dcce8-e13c-4f2f-a9c7-adea4354ec9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>ISO3 Code</th>\n",
       "      <th>Datetime (UTC)</th>\n",
       "      <th>Datetime (Local)</th>\n",
       "      <th>Price (EUR/MWhe)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35063</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2018-12-31 23:00:00</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35064</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>46.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>39.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35066</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>27.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35067</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>23.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87617</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2024-12-29 17:00:00</td>\n",
       "      <td>2024-12-29 18:00:00</td>\n",
       "      <td>134.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87618</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2024-12-29 18:00:00</td>\n",
       "      <td>2024-12-29 19:00:00</td>\n",
       "      <td>133.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87619</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2024-12-29 19:00:00</td>\n",
       "      <td>2024-12-29 20:00:00</td>\n",
       "      <td>123.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87620</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2024-12-29 20:00:00</td>\n",
       "      <td>2024-12-29 21:00:00</td>\n",
       "      <td>118.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87621</th>\n",
       "      <td>France</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2024-12-29 21:00:00</td>\n",
       "      <td>2024-12-29 22:00:00</td>\n",
       "      <td>118.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52559 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country ISO3 Code       Datetime (UTC)     Datetime (Local)  \\\n",
       "35063  France       FRA  2018-12-31 23:00:00  2019-01-01 00:00:00   \n",
       "35064  France       FRA  2019-01-01 00:00:00  2019-01-01 01:00:00   \n",
       "35065  France       FRA  2019-01-01 01:00:00  2019-01-01 02:00:00   \n",
       "35066  France       FRA  2019-01-01 02:00:00  2019-01-01 03:00:00   \n",
       "35067  France       FRA  2019-01-01 03:00:00  2019-01-01 04:00:00   \n",
       "...       ...       ...                  ...                  ...   \n",
       "87617  France       FRA  2024-12-29 17:00:00  2024-12-29 18:00:00   \n",
       "87618  France       FRA  2024-12-29 18:00:00  2024-12-29 19:00:00   \n",
       "87619  France       FRA  2024-12-29 19:00:00  2024-12-29 20:00:00   \n",
       "87620  France       FRA  2024-12-29 20:00:00  2024-12-29 21:00:00   \n",
       "87621  France       FRA  2024-12-29 21:00:00  2024-12-29 22:00:00   \n",
       "\n",
       "       Price (EUR/MWhe)  \n",
       "35063             51.00  \n",
       "35064             46.27  \n",
       "35065             39.78  \n",
       "35066             27.87  \n",
       "35067             23.21  \n",
       "...                 ...  \n",
       "87617            134.40  \n",
       "87618            133.72  \n",
       "87619            123.92  \n",
       "87620            118.59  \n",
       "87621            118.59  \n",
       "\n",
       "[52559 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad37821e-6abf-410d-bce3-800a65d07274",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_period.drop(['Country','ISO3 Code','Datetime (UTC)'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "506668c6-5be4-4846-98f5-aa3f15d752f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_period['Datetime (Local)'] = pd.to_datetime(prices_period['Datetime (Local)'])\n",
    "whole_period = prices_period.merge(use_data,how='left',left_on='Datetime (Local)',\n",
    "                                  right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2968e344-69f3-4fa1-adf2-18d1b67df265",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period.drop('Datetime (Local)',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d77bc7bf-d6d9-4102-a279-bf6e62716ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Price (EUR/MWhe)', 'Date', 'Consommation', 'Fioul', 'Charbon', 'Gaz',\n",
       "       'Nucléaire', 'Eolien', 'Solaire', 'Hydraulique', 'Pompage',\n",
       "       'Bioénergies', 'Ech. physiques', 'Taux de Co2', 'Ech. comm. Angleterre',\n",
       "       'Ech. comm. Espagne', 'Ech. comm. Italie', 'Ech. comm. Suisse',\n",
       "       'Ech. comm. Allemagne-Belgique', 'Fioul - TAC', 'Fioul - Cogén.',\n",
       "       'Fioul - Autres', 'Gaz - TAC', 'Gaz - Cogén.', 'Gaz - CCG',\n",
       "       'Gaz - Autres', 'Hydraulique - Fil de l?eau + éclusée',\n",
       "       'Hydraulique - Lacs', 'Hydraulique - STEP turbinage',\n",
       "       'Bioénergies - Déchets', 'Bioénergies - Biomasse',\n",
       "       'Bioénergies - Biogaz', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_period.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09d23912-ca25-452a-9619-896331d80950",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period.columns = ['price','date_wo_h','conso','fioul','coal','gas',\n",
    "                       'nuclear','wind','sun','hydro','pump','bioenergy','physics',\n",
    "                        'exchange_uk','exchange_sp','exchange_it','exchange_sw',\n",
    "                        'exchange_gr','co2_rate','fioul_tac','fioul_cogen',\n",
    "                        'fioul_other','gas_tac',\n",
    "                       'gas_cogen','gas_ccg','gas_other','hydro_river','hydro_lake',\n",
    "                       'hydro_turbine','bio_waste','bio_biomass','bio_biogas','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b3afd67-665e-4f9c-b10c-1fcf490c8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b3040fe-d1a0-4a06-acd5-5e313093dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole_period['target_date'] = whole_period['date'] + timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22bedb4-edfe-4fdd-aaf3-2f18fcc5c88c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(whole_period['date'],whole_period['price'])\n",
    "ax.tick_params(axis='x', labelrotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc178037-01af-458f-babf-af394fa7862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period['cos_day'] = whole_period['date'].dt.day.astype(float)\n",
    "whole_period['sin_day'] = whole_period['date'].dt.day.astype(float)\n",
    "whole_period['cos_month'] = whole_period['date'].dt.month.astype(float)\n",
    "whole_period['sin_month'] = whole_period['date'].dt.month.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f41043b-9b07-49d9-b485-71663cfa3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period['cos_day'] = cos_transformer(365).fit_transform(whole_period['cos_day'])\n",
    "whole_period['cos_month'] = cos_transformer(12).fit_transform(whole_period['cos_month'])\n",
    "whole_period['sin_day'] = sin_transformer(365).fit_transform(whole_period['sin_day'])\n",
    "whole_period['sin_month'] = sin_transformer(12).fit_transform(whole_period['sin_month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68f4e0ba-b313-4f36-b9f6-ec1bb0473915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig, ax = plt.subplots()\n",
    "for i in ['cos_day','sin_day','cos_month','sin_month']:\n",
    "    ax.plot(whole_period[f'{i}'],label=f'{i}')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb869990-a823-4a2a-81c5-52be5aaeec0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole_period[whole_period['date'] < '2019-01-02 01:00:00' & whole_period['date'] <'2019-01-03 01:00:00' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a208230-5d25-45d5-be5c-a190d1810784",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period['weekdays'] = whole_period['date'].dt.dayofweek\n",
    "whole_period['weekend'] = np.zeros(whole_period.shape[0])\n",
    "whole_period['not_weekend'] = np.zeros(whole_period.shape[0])\n",
    "whole_period['date_wo_h'] = pd.to_datetime(whole_period['date_wo_h'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f732e6c-171d-45db-a8d7-720364723868",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(whole_period.shape[0]):\n",
    "    if whole_period.loc[i,'weekdays'] == 5 or whole_period.loc[i,'weekdays'] == 6:\n",
    "        whole_period.loc[i,'weekend'] = 1\n",
    "    else:\n",
    "        whole_period.loc[i,'not_weekend'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd1e9628-5b8c-4a7a-bbd7-4a455adedb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to add the 2 days lagged of fossil fuel and nuclear production\n",
    "#we cannot add what they call the announced availability because they don't \n",
    "#describe how they find it and on the majority of ressources concerning \n",
    "#the matter, we only have access to the effective production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c51a5cc-f820-4bd4-9d3b-5662bd324a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period['2_lags_coal'] = whole_period['coal'].shift(48)\n",
    "whole_period['2_lags_fioul'] = whole_period['fioul'].shift(48)\n",
    "whole_period['2_lags_gas'] = whole_period['gas'].shift(48)\n",
    "whole_period['2_lags_nuke'] = whole_period['nuclear'].shift(48)\n",
    "whole_period['target_price'] = whole_period['price'].shift(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c73ef5da-9164-4ff8-aa4b-d34313626424",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_period.dropna(inplace=True) #we just loose two days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d0cac5b-3418-4a85-b68d-ed9014542691",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = whole_period[whole_period['date_wo_h'].dt.year < 2022].copy()\n",
    "test_data = whole_period[whole_period['date_wo_h'].dt.year == 2022].copy()\n",
    "list_imp_hours = [3,8,13,18,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3b796a0-b6af-47aa-9db7-1faa2683ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.drop(['price'],axis=1,inplace=True)\n",
    "test_data.drop(['price'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59749cf1-6d5a-473e-a34c-331ce5e8cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data[training_data['date'].dt.hour.isin(list_imp_hours)]\n",
    "test_data = test_data[test_data['date'].dt.hour.isin(list_imp_hours)]\n",
    "for_plots_date = test_data['date']\n",
    "for_plots_train = training_data['date']\n",
    "training_data.reset_index(inplace=True,drop=True)\n",
    "test_data.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41d7a799-af22-4739-b8e4-a5898c0b902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_imp = list(training_data.columns) #list of features to keep for the koopman operator, as \n",
    "#it might be very computational demanding\n",
    "list_imp.remove('date')\n",
    "list_imp.remove('date_wo_h')\n",
    "#['nuclear','2_lags_nuke','coal','exchange_uk','fioul','target_price']\n",
    "y_train = np.array(training_data['target_price'])\n",
    "y_test = np.array(test_data['target_price'])\n",
    "\n",
    "\n",
    "#creation of the koopman train and test set\n",
    "#different from the previous one as we have to\n",
    "#keep all variables\n",
    "koop_train = training_data[list_imp].copy()\n",
    "koop_test = test_data[list_imp].copy()\n",
    "koop_train['target_last'] = koop_train['target_price'].copy()\n",
    "koop_test['target_last'] = koop_test['target_price'].copy()\n",
    "koop_train.drop(['target_price'],axis=1,inplace=True)\n",
    "koop_test.drop(['target_price'],axis=1,inplace=True)\n",
    "scaler_koop = StandardScaler().fit(koop_train)\n",
    "koop_train = scaler_koop.transform(koop_train)\n",
    "koop_test = scaler_koop.transform(koop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3969f3e-943b-4eae-8e71-ef196db181bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_reg_05 = QuantileRegressor(quantile=0.05).fit(X=training_data,\n",
    "                                                      y=y_train)\n",
    "quantile_reg_95 = QuantileRegressor(quantile=0.95).fit(X=training_data,\n",
    "                                                      y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5784af7a-d071-45b0-93ea-240b21e5a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_05 = quantile_reg_05.predict(X=test_data)\n",
    "predictions_95 = quantile_reg_95.predict(X=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db0fd524-0c23-456f-b107-dcc15d9abcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dates = pd.date_range(start='2019-01-03',end='2019-01-14',freq='h')\n",
    "training_dates = training_dates[training_dates.hour.isin(list_imp_hours)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d9621-ab01-47e0-bdc0-978bef1aeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_array = np.zeros((0,2))\n",
    "#need to find a way to keep a constant window\n",
    "for day in training_dates:\n",
    "    day_data = training_data[training_data['date_wo_h'] == day].copy()\n",
    "    compteur = 0\n",
    "    for hour in list_imp_hours:\n",
    "        pred_array = np.zeros((1,2))\n",
    "        accessible_data = day_data[day_data['date'].dt.hour <= hour]\n",
    "        quantile_05_temp = QuantileRegressor(quantile=0.05).fit(X=accessible_data.drop(['date','date_wo_h','target_price']),\n",
    "                                                                y=accessible_data['target_price'])\n",
    "        quantile_95_temp = QuantileRegressor(quantile=0.95).fit(X=accessible_data.drop(['date','date_wo_h','target_price']),\n",
    "                                                                y=accessible_data['target_price'])\n",
    "        next_day = accessible_data.loc[4,'date'] + pd.offsets.Day(1) \n",
    "        #from here ok to gen because we always want\n",
    "        #to predict the following day\n",
    "        pred_0 = quantile_05_temp.predict(training_data[training_data['date'] == next_day])\n",
    "        pred_1 = quantile_95_temp.predict(training_data[training_data['date'] == next_day])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8f8c579-e7b4-4ec4-82e6-ceb8e0ded9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = training_dates[training_dates.hour.isin(list_imp_hours)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b3aa38a-2592-4c85-aa06-7d340e4d8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2019-01-03 03:00:00', '2019-01-03 08:00:00',\n",
      "               '2019-01-03 13:00:00', '2019-01-03 18:00:00',\n",
      "               '2019-01-03 23:00:00', '2019-01-04 03:00:00',\n",
      "               '2019-01-04 08:00:00', '2019-01-04 13:00:00',\n",
      "               '2019-01-04 18:00:00', '2019-01-04 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-03 08:00:00', '2019-01-03 13:00:00',\n",
      "               '2019-01-03 18:00:00', '2019-01-03 23:00:00',\n",
      "               '2019-01-04 03:00:00', '2019-01-04 08:00:00',\n",
      "               '2019-01-04 13:00:00', '2019-01-04 18:00:00',\n",
      "               '2019-01-04 23:00:00', '2019-01-05 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-03 13:00:00', '2019-01-03 18:00:00',\n",
      "               '2019-01-03 23:00:00', '2019-01-04 03:00:00',\n",
      "               '2019-01-04 08:00:00', '2019-01-04 13:00:00',\n",
      "               '2019-01-04 18:00:00', '2019-01-04 23:00:00',\n",
      "               '2019-01-05 03:00:00', '2019-01-05 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-03 18:00:00', '2019-01-03 23:00:00',\n",
      "               '2019-01-04 03:00:00', '2019-01-04 08:00:00',\n",
      "               '2019-01-04 13:00:00', '2019-01-04 18:00:00',\n",
      "               '2019-01-04 23:00:00', '2019-01-05 03:00:00',\n",
      "               '2019-01-05 08:00:00', '2019-01-05 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-03 23:00:00', '2019-01-04 03:00:00',\n",
      "               '2019-01-04 08:00:00', '2019-01-04 13:00:00',\n",
      "               '2019-01-04 18:00:00', '2019-01-04 23:00:00',\n",
      "               '2019-01-05 03:00:00', '2019-01-05 08:00:00',\n",
      "               '2019-01-05 13:00:00', '2019-01-05 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-04 03:00:00', '2019-01-04 08:00:00',\n",
      "               '2019-01-04 13:00:00', '2019-01-04 18:00:00',\n",
      "               '2019-01-04 23:00:00', '2019-01-05 03:00:00',\n",
      "               '2019-01-05 08:00:00', '2019-01-05 13:00:00',\n",
      "               '2019-01-05 18:00:00', '2019-01-05 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-04 08:00:00', '2019-01-04 13:00:00',\n",
      "               '2019-01-04 18:00:00', '2019-01-04 23:00:00',\n",
      "               '2019-01-05 03:00:00', '2019-01-05 08:00:00',\n",
      "               '2019-01-05 13:00:00', '2019-01-05 18:00:00',\n",
      "               '2019-01-05 23:00:00', '2019-01-06 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-04 13:00:00', '2019-01-04 18:00:00',\n",
      "               '2019-01-04 23:00:00', '2019-01-05 03:00:00',\n",
      "               '2019-01-05 08:00:00', '2019-01-05 13:00:00',\n",
      "               '2019-01-05 18:00:00', '2019-01-05 23:00:00',\n",
      "               '2019-01-06 03:00:00', '2019-01-06 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-04 18:00:00', '2019-01-04 23:00:00',\n",
      "               '2019-01-05 03:00:00', '2019-01-05 08:00:00',\n",
      "               '2019-01-05 13:00:00', '2019-01-05 18:00:00',\n",
      "               '2019-01-05 23:00:00', '2019-01-06 03:00:00',\n",
      "               '2019-01-06 08:00:00', '2019-01-06 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-04 23:00:00', '2019-01-05 03:00:00',\n",
      "               '2019-01-05 08:00:00', '2019-01-05 13:00:00',\n",
      "               '2019-01-05 18:00:00', '2019-01-05 23:00:00',\n",
      "               '2019-01-06 03:00:00', '2019-01-06 08:00:00',\n",
      "               '2019-01-06 13:00:00', '2019-01-06 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-05 03:00:00', '2019-01-05 08:00:00',\n",
      "               '2019-01-05 13:00:00', '2019-01-05 18:00:00',\n",
      "               '2019-01-05 23:00:00', '2019-01-06 03:00:00',\n",
      "               '2019-01-06 08:00:00', '2019-01-06 13:00:00',\n",
      "               '2019-01-06 18:00:00', '2019-01-06 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-05 08:00:00', '2019-01-05 13:00:00',\n",
      "               '2019-01-05 18:00:00', '2019-01-05 23:00:00',\n",
      "               '2019-01-06 03:00:00', '2019-01-06 08:00:00',\n",
      "               '2019-01-06 13:00:00', '2019-01-06 18:00:00',\n",
      "               '2019-01-06 23:00:00', '2019-01-07 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-05 13:00:00', '2019-01-05 18:00:00',\n",
      "               '2019-01-05 23:00:00', '2019-01-06 03:00:00',\n",
      "               '2019-01-06 08:00:00', '2019-01-06 13:00:00',\n",
      "               '2019-01-06 18:00:00', '2019-01-06 23:00:00',\n",
      "               '2019-01-07 03:00:00', '2019-01-07 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-05 18:00:00', '2019-01-05 23:00:00',\n",
      "               '2019-01-06 03:00:00', '2019-01-06 08:00:00',\n",
      "               '2019-01-06 13:00:00', '2019-01-06 18:00:00',\n",
      "               '2019-01-06 23:00:00', '2019-01-07 03:00:00',\n",
      "               '2019-01-07 08:00:00', '2019-01-07 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-05 23:00:00', '2019-01-06 03:00:00',\n",
      "               '2019-01-06 08:00:00', '2019-01-06 13:00:00',\n",
      "               '2019-01-06 18:00:00', '2019-01-06 23:00:00',\n",
      "               '2019-01-07 03:00:00', '2019-01-07 08:00:00',\n",
      "               '2019-01-07 13:00:00', '2019-01-07 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-06 03:00:00', '2019-01-06 08:00:00',\n",
      "               '2019-01-06 13:00:00', '2019-01-06 18:00:00',\n",
      "               '2019-01-06 23:00:00', '2019-01-07 03:00:00',\n",
      "               '2019-01-07 08:00:00', '2019-01-07 13:00:00',\n",
      "               '2019-01-07 18:00:00', '2019-01-07 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-06 08:00:00', '2019-01-06 13:00:00',\n",
      "               '2019-01-06 18:00:00', '2019-01-06 23:00:00',\n",
      "               '2019-01-07 03:00:00', '2019-01-07 08:00:00',\n",
      "               '2019-01-07 13:00:00', '2019-01-07 18:00:00',\n",
      "               '2019-01-07 23:00:00', '2019-01-08 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-06 13:00:00', '2019-01-06 18:00:00',\n",
      "               '2019-01-06 23:00:00', '2019-01-07 03:00:00',\n",
      "               '2019-01-07 08:00:00', '2019-01-07 13:00:00',\n",
      "               '2019-01-07 18:00:00', '2019-01-07 23:00:00',\n",
      "               '2019-01-08 03:00:00', '2019-01-08 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-06 18:00:00', '2019-01-06 23:00:00',\n",
      "               '2019-01-07 03:00:00', '2019-01-07 08:00:00',\n",
      "               '2019-01-07 13:00:00', '2019-01-07 18:00:00',\n",
      "               '2019-01-07 23:00:00', '2019-01-08 03:00:00',\n",
      "               '2019-01-08 08:00:00', '2019-01-08 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-06 23:00:00', '2019-01-07 03:00:00',\n",
      "               '2019-01-07 08:00:00', '2019-01-07 13:00:00',\n",
      "               '2019-01-07 18:00:00', '2019-01-07 23:00:00',\n",
      "               '2019-01-08 03:00:00', '2019-01-08 08:00:00',\n",
      "               '2019-01-08 13:00:00', '2019-01-08 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-07 03:00:00', '2019-01-07 08:00:00',\n",
      "               '2019-01-07 13:00:00', '2019-01-07 18:00:00',\n",
      "               '2019-01-07 23:00:00', '2019-01-08 03:00:00',\n",
      "               '2019-01-08 08:00:00', '2019-01-08 13:00:00',\n",
      "               '2019-01-08 18:00:00', '2019-01-08 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-07 08:00:00', '2019-01-07 13:00:00',\n",
      "               '2019-01-07 18:00:00', '2019-01-07 23:00:00',\n",
      "               '2019-01-08 03:00:00', '2019-01-08 08:00:00',\n",
      "               '2019-01-08 13:00:00', '2019-01-08 18:00:00',\n",
      "               '2019-01-08 23:00:00', '2019-01-09 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-07 13:00:00', '2019-01-07 18:00:00',\n",
      "               '2019-01-07 23:00:00', '2019-01-08 03:00:00',\n",
      "               '2019-01-08 08:00:00', '2019-01-08 13:00:00',\n",
      "               '2019-01-08 18:00:00', '2019-01-08 23:00:00',\n",
      "               '2019-01-09 03:00:00', '2019-01-09 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-07 18:00:00', '2019-01-07 23:00:00',\n",
      "               '2019-01-08 03:00:00', '2019-01-08 08:00:00',\n",
      "               '2019-01-08 13:00:00', '2019-01-08 18:00:00',\n",
      "               '2019-01-08 23:00:00', '2019-01-09 03:00:00',\n",
      "               '2019-01-09 08:00:00', '2019-01-09 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-07 23:00:00', '2019-01-08 03:00:00',\n",
      "               '2019-01-08 08:00:00', '2019-01-08 13:00:00',\n",
      "               '2019-01-08 18:00:00', '2019-01-08 23:00:00',\n",
      "               '2019-01-09 03:00:00', '2019-01-09 08:00:00',\n",
      "               '2019-01-09 13:00:00', '2019-01-09 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-08 03:00:00', '2019-01-08 08:00:00',\n",
      "               '2019-01-08 13:00:00', '2019-01-08 18:00:00',\n",
      "               '2019-01-08 23:00:00', '2019-01-09 03:00:00',\n",
      "               '2019-01-09 08:00:00', '2019-01-09 13:00:00',\n",
      "               '2019-01-09 18:00:00', '2019-01-09 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-08 08:00:00', '2019-01-08 13:00:00',\n",
      "               '2019-01-08 18:00:00', '2019-01-08 23:00:00',\n",
      "               '2019-01-09 03:00:00', '2019-01-09 08:00:00',\n",
      "               '2019-01-09 13:00:00', '2019-01-09 18:00:00',\n",
      "               '2019-01-09 23:00:00', '2019-01-10 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-08 13:00:00', '2019-01-08 18:00:00',\n",
      "               '2019-01-08 23:00:00', '2019-01-09 03:00:00',\n",
      "               '2019-01-09 08:00:00', '2019-01-09 13:00:00',\n",
      "               '2019-01-09 18:00:00', '2019-01-09 23:00:00',\n",
      "               '2019-01-10 03:00:00', '2019-01-10 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-08 18:00:00', '2019-01-08 23:00:00',\n",
      "               '2019-01-09 03:00:00', '2019-01-09 08:00:00',\n",
      "               '2019-01-09 13:00:00', '2019-01-09 18:00:00',\n",
      "               '2019-01-09 23:00:00', '2019-01-10 03:00:00',\n",
      "               '2019-01-10 08:00:00', '2019-01-10 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-08 23:00:00', '2019-01-09 03:00:00',\n",
      "               '2019-01-09 08:00:00', '2019-01-09 13:00:00',\n",
      "               '2019-01-09 18:00:00', '2019-01-09 23:00:00',\n",
      "               '2019-01-10 03:00:00', '2019-01-10 08:00:00',\n",
      "               '2019-01-10 13:00:00', '2019-01-10 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-09 03:00:00', '2019-01-09 08:00:00',\n",
      "               '2019-01-09 13:00:00', '2019-01-09 18:00:00',\n",
      "               '2019-01-09 23:00:00', '2019-01-10 03:00:00',\n",
      "               '2019-01-10 08:00:00', '2019-01-10 13:00:00',\n",
      "               '2019-01-10 18:00:00', '2019-01-10 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-09 08:00:00', '2019-01-09 13:00:00',\n",
      "               '2019-01-09 18:00:00', '2019-01-09 23:00:00',\n",
      "               '2019-01-10 03:00:00', '2019-01-10 08:00:00',\n",
      "               '2019-01-10 13:00:00', '2019-01-10 18:00:00',\n",
      "               '2019-01-10 23:00:00', '2019-01-11 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-09 13:00:00', '2019-01-09 18:00:00',\n",
      "               '2019-01-09 23:00:00', '2019-01-10 03:00:00',\n",
      "               '2019-01-10 08:00:00', '2019-01-10 13:00:00',\n",
      "               '2019-01-10 18:00:00', '2019-01-10 23:00:00',\n",
      "               '2019-01-11 03:00:00', '2019-01-11 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-09 18:00:00', '2019-01-09 23:00:00',\n",
      "               '2019-01-10 03:00:00', '2019-01-10 08:00:00',\n",
      "               '2019-01-10 13:00:00', '2019-01-10 18:00:00',\n",
      "               '2019-01-10 23:00:00', '2019-01-11 03:00:00',\n",
      "               '2019-01-11 08:00:00', '2019-01-11 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-09 23:00:00', '2019-01-10 03:00:00',\n",
      "               '2019-01-10 08:00:00', '2019-01-10 13:00:00',\n",
      "               '2019-01-10 18:00:00', '2019-01-10 23:00:00',\n",
      "               '2019-01-11 03:00:00', '2019-01-11 08:00:00',\n",
      "               '2019-01-11 13:00:00', '2019-01-11 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-10 03:00:00', '2019-01-10 08:00:00',\n",
      "               '2019-01-10 13:00:00', '2019-01-10 18:00:00',\n",
      "               '2019-01-10 23:00:00', '2019-01-11 03:00:00',\n",
      "               '2019-01-11 08:00:00', '2019-01-11 13:00:00',\n",
      "               '2019-01-11 18:00:00', '2019-01-11 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-10 08:00:00', '2019-01-10 13:00:00',\n",
      "               '2019-01-10 18:00:00', '2019-01-10 23:00:00',\n",
      "               '2019-01-11 03:00:00', '2019-01-11 08:00:00',\n",
      "               '2019-01-11 13:00:00', '2019-01-11 18:00:00',\n",
      "               '2019-01-11 23:00:00', '2019-01-12 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-10 13:00:00', '2019-01-10 18:00:00',\n",
      "               '2019-01-10 23:00:00', '2019-01-11 03:00:00',\n",
      "               '2019-01-11 08:00:00', '2019-01-11 13:00:00',\n",
      "               '2019-01-11 18:00:00', '2019-01-11 23:00:00',\n",
      "               '2019-01-12 03:00:00', '2019-01-12 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-10 18:00:00', '2019-01-10 23:00:00',\n",
      "               '2019-01-11 03:00:00', '2019-01-11 08:00:00',\n",
      "               '2019-01-11 13:00:00', '2019-01-11 18:00:00',\n",
      "               '2019-01-11 23:00:00', '2019-01-12 03:00:00',\n",
      "               '2019-01-12 08:00:00', '2019-01-12 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-10 23:00:00', '2019-01-11 03:00:00',\n",
      "               '2019-01-11 08:00:00', '2019-01-11 13:00:00',\n",
      "               '2019-01-11 18:00:00', '2019-01-11 23:00:00',\n",
      "               '2019-01-12 03:00:00', '2019-01-12 08:00:00',\n",
      "               '2019-01-12 13:00:00', '2019-01-12 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-11 03:00:00', '2019-01-11 08:00:00',\n",
      "               '2019-01-11 13:00:00', '2019-01-11 18:00:00',\n",
      "               '2019-01-11 23:00:00', '2019-01-12 03:00:00',\n",
      "               '2019-01-12 08:00:00', '2019-01-12 13:00:00',\n",
      "               '2019-01-12 18:00:00', '2019-01-12 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-11 08:00:00', '2019-01-11 13:00:00',\n",
      "               '2019-01-11 18:00:00', '2019-01-11 23:00:00',\n",
      "               '2019-01-12 03:00:00', '2019-01-12 08:00:00',\n",
      "               '2019-01-12 13:00:00', '2019-01-12 18:00:00',\n",
      "               '2019-01-12 23:00:00', '2019-01-13 03:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-11 13:00:00', '2019-01-11 18:00:00',\n",
      "               '2019-01-11 23:00:00', '2019-01-12 03:00:00',\n",
      "               '2019-01-12 08:00:00', '2019-01-12 13:00:00',\n",
      "               '2019-01-12 18:00:00', '2019-01-12 23:00:00',\n",
      "               '2019-01-13 03:00:00', '2019-01-13 08:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-11 18:00:00', '2019-01-11 23:00:00',\n",
      "               '2019-01-12 03:00:00', '2019-01-12 08:00:00',\n",
      "               '2019-01-12 13:00:00', '2019-01-12 18:00:00',\n",
      "               '2019-01-12 23:00:00', '2019-01-13 03:00:00',\n",
      "               '2019-01-13 08:00:00', '2019-01-13 13:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-11 23:00:00', '2019-01-12 03:00:00',\n",
      "               '2019-01-12 08:00:00', '2019-01-12 13:00:00',\n",
      "               '2019-01-12 18:00:00', '2019-01-12 23:00:00',\n",
      "               '2019-01-13 03:00:00', '2019-01-13 08:00:00',\n",
      "               '2019-01-13 13:00:00', '2019-01-13 18:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-12 03:00:00', '2019-01-12 08:00:00',\n",
      "               '2019-01-12 13:00:00', '2019-01-12 18:00:00',\n",
      "               '2019-01-12 23:00:00', '2019-01-13 03:00:00',\n",
      "               '2019-01-13 08:00:00', '2019-01-13 13:00:00',\n",
      "               '2019-01-13 18:00:00', '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-12 08:00:00', '2019-01-12 13:00:00',\n",
      "               '2019-01-12 18:00:00', '2019-01-12 23:00:00',\n",
      "               '2019-01-13 03:00:00', '2019-01-13 08:00:00',\n",
      "               '2019-01-13 13:00:00', '2019-01-13 18:00:00',\n",
      "               '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-12 13:00:00', '2019-01-12 18:00:00',\n",
      "               '2019-01-12 23:00:00', '2019-01-13 03:00:00',\n",
      "               '2019-01-13 08:00:00', '2019-01-13 13:00:00',\n",
      "               '2019-01-13 18:00:00', '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-12 18:00:00', '2019-01-12 23:00:00',\n",
      "               '2019-01-13 03:00:00', '2019-01-13 08:00:00',\n",
      "               '2019-01-13 13:00:00', '2019-01-13 18:00:00',\n",
      "               '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-12 23:00:00', '2019-01-13 03:00:00',\n",
      "               '2019-01-13 08:00:00', '2019-01-13 13:00:00',\n",
      "               '2019-01-13 18:00:00', '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-13 03:00:00', '2019-01-13 08:00:00',\n",
      "               '2019-01-13 13:00:00', '2019-01-13 18:00:00',\n",
      "               '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-13 08:00:00', '2019-01-13 13:00:00',\n",
      "               '2019-01-13 18:00:00', '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-13 13:00:00', '2019-01-13 18:00:00',\n",
      "               '2019-01-13 23:00:00'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-13 18:00:00', '2019-01-13 23:00:00'], dtype='datetime64[ns]', freq=None)\n",
      "DatetimeIndex(['2019-01-13 23:00:00'], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "for i in range(test_1.shape[0]):\n",
    "    print(test_1[i:i+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b8939-2c69-4686-90b2-60cde4337a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
